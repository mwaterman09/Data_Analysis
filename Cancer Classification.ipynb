{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M        17.99         10.38          122.80     1001.0   \n",
       "1      842517         M        20.57         17.77          132.90     1326.0   \n",
       "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3    84348301         M        11.42         20.38           77.58      386.1   \n",
       "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M        21.56         22.39          142.00     1479.0   \n",
       "565    926682         M        20.13         28.25          131.20     1261.0   \n",
       "566    926954         M        16.60         28.08          108.30      858.1   \n",
       "567    927241         M        20.60         29.33          140.10     1265.0   \n",
       "568     92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0    ...          17.33           184.60      2019.0           0.16220   \n",
       "1    ...          23.41           158.80      1956.0           0.12380   \n",
       "2    ...          25.53           152.50      1709.0           0.14440   \n",
       "3    ...          26.50            98.87       567.7           0.20980   \n",
       "4    ...          16.67           152.20      1575.0           0.13740   \n",
       "..   ...            ...              ...         ...               ...   \n",
       "564  ...          26.40           166.10      2027.0           0.14100   \n",
       "565  ...          38.25           155.00      1731.0           0.11660   \n",
       "566  ...          34.12           126.70      1124.0           0.11390   \n",
       "567  ...          39.42           184.60      1821.0           0.16500   \n",
       "568  ...          30.37            59.16       268.6           0.08996   \n",
       "\n",
       "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0              0.66560           0.7119                0.2654          0.4601   \n",
       "1              0.18660           0.2416                0.1860          0.2750   \n",
       "2              0.42450           0.4504                0.2430          0.3613   \n",
       "3              0.86630           0.6869                0.2575          0.6638   \n",
       "4              0.20500           0.4000                0.1625          0.2364   \n",
       "..                 ...              ...                   ...             ...   \n",
       "564            0.21130           0.4107                0.2216          0.2060   \n",
       "565            0.19220           0.3215                0.1628          0.2572   \n",
       "566            0.30940           0.3403                0.1418          0.2218   \n",
       "567            0.86810           0.9387                0.2650          0.4087   \n",
       "568            0.06444           0.0000                0.0000          0.2871   \n",
       "\n",
       "     fractal_dimension_worst  Unnamed: 32  \n",
       "0                    0.11890          NaN  \n",
       "1                    0.08902          NaN  \n",
       "2                    0.08758          NaN  \n",
       "3                    0.17300          NaN  \n",
       "4                    0.07678          NaN  \n",
       "..                       ...          ...  \n",
       "564                  0.07115          NaN  \n",
       "565                  0.06637          NaN  \n",
       "566                  0.07820          NaN  \n",
       "567                  0.12400          NaN  \n",
       "568                  0.07039          NaN  \n",
       "\n",
       "[569 rows x 33 columns]"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "df = pd.read_csv('Cancer_Data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "diagnosis                    0\n",
       "radius_mean                  0\n",
       "texture_mean                 0\n",
       "perimeter_mean               0\n",
       "area_mean                    0\n",
       "smoothness_mean              0\n",
       "compactness_mean             0\n",
       "concavity_mean               0\n",
       "concave points_mean          0\n",
       "symmetry_mean                0\n",
       "fractal_dimension_mean       0\n",
       "radius_se                    0\n",
       "texture_se                   0\n",
       "perimeter_se                 0\n",
       "area_se                      0\n",
       "smoothness_se                0\n",
       "compactness_se               0\n",
       "concavity_se                 0\n",
       "concave points_se            0\n",
       "symmetry_se                  0\n",
       "fractal_dimension_se         0\n",
       "radius_worst                 0\n",
       "texture_worst                0\n",
       "perimeter_worst              0\n",
       "area_worst                   0\n",
       "smoothness_worst             0\n",
       "compactness_worst            0\n",
       "concavity_worst              0\n",
       "concave points_worst         0\n",
       "symmetry_worst               0\n",
       "fractal_dimension_worst      0\n",
       "Unnamed: 32                569\n",
       "dtype: int64"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of malignant: 212, number of benign: 357\n"
     ]
    }
   ],
   "source": [
    "# count how many benign and malignant entries there are\n",
    "total_m = 0\n",
    "for diagnosis in df['diagnosis']:\n",
    "    if diagnosis == 'M':\n",
    "        total_m += 1\n",
    "\n",
    "total_b = 569 - total_m\n",
    "print(f'Number of malignant: {total_m}, number of benign: {total_b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into X and y sections\n",
    "X = df.iloc[:, 2:19].values\n",
    "y = df.iloc[:, [1]].values #.reshape(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B' 'M']\n"
     ]
    }
   ],
   "source": [
    "# encode binary classes 'M' and 'B'into integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y.ravel())\n",
    "y = encoder.transform(y.ravel())\n",
    "print(encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 2d torch tensors\n",
    "X = torch.from_numpy(X).float()\n",
    "y = torch.from_numpy(y).float()\n",
    "y = y.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([455, 17]), y_train: torch.Size([455, 1]), X_test: torch.Size([114, 17]), y_test: torch.Size([114, 1])\n"
     ]
    }
   ],
   "source": [
    "# check dimensions\n",
    "print(f'X_train: {X_train.shape}, y_train: {y_train.shape}, X_test: {X_test.shape}, y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign number of samples and features for model input\n",
    "n_samples, n_features = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define size of the network - more hidden neurons is called a 'wider' model, more layers is called 'deeper'\n",
    "input_size = n_features\n",
    "hidden_size = 3 \n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model class\n",
    "class CancerModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(CancerModel, self).__init__()\n",
    "\n",
    "        # define layers\n",
    "        self.layer_1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.layer_2 = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    # define forward pass\n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer_2(x)\n",
    "        yhat = self.sigmoid(x)\n",
    "        \n",
    "\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = CancerModel(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer and criterion for loss\n",
    "criterion = nn.BCELoss() # binary cross entropy loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "epochs = 500\n",
    "total_loss = []\n",
    "\n",
    "# outer loop repeats training process\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    Yhat = model(X_train)\n",
    "    loss_batch = criterion(Yhat, y_train)\n",
    "    total_loss.append(loss_batch.item())\n",
    "\n",
    "    # inner loop consists of forward pass and backpropagation\n",
    "    for x, y in zip(X_train, y_train):\n",
    "\n",
    "        yhat = model(x)\n",
    "        \n",
    "        loss = criterion(yhat, y)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer.zero_grad()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss function\n",
    "x_line = range(epochs)\n",
    "plt.plot(x_line, total_loss)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "prediction = model(X_test).detach().numpy()\n",
    "prediction = prediction.round() # round to either 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114,)"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = prediction.squeeze(1)\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model accuracy is 93.860 %.\n"
     ]
    }
   ],
   "source": [
    "# accuracy of predictions\n",
    "n_correct = 0.0\n",
    "\n",
    "for x, y in zip(prediction, y_test):\n",
    "\n",
    "    if x == y:\n",
    "        n_correct += 1\n",
    "\n",
    "accuracy = (n_correct/len(y_test))*100\n",
    "print(f'The model accuracy is {accuracy:.3f} %.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
